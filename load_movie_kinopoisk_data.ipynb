{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "page = 1\n",
    "url_tmpl = 'http://www.kinopoisk.ru/top/navigator/m_act[num_vote]/100/m_act[rating]/1:/order/rating/page/%d/#results'\n",
    "url = url_tmpl % page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# initialize session\n",
    "s = requests.Session() \n",
    "s.headers.update({\n",
    "        'Referer': 'http://www.kinopoisk.ru',\n",
    "        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:45.0) Gecko/20100101 Firefox/45.0'\n",
    "        #'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/49.0.2623.110 Safari/537.36'\n",
    "    })\n",
    "\n",
    "pattern = re.compile('.*/(\\d+)/?$') # pattern to get movie_id from link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: all_movies_list: File exists\n",
      "\u001b[34mall_movies_data_thread\u001b[m\u001b[m       loading_movies_kp_data.ipynb\n",
      "\u001b[34mall_movies_list\u001b[m\u001b[m              \u001b[34muser_data\u001b[m\u001b[m\n",
      "all_movies_list.csv\n"
     ]
    }
   ],
   "source": [
    "! mkdir all_movies_list\n",
    "! ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Список фильмов\n",
    "## Загружаем список всех фильмов \n",
    "Будем брать все фильмы у которых есть хотя бы 100 оценок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# loading list of all movies with at least 100 votes\n",
    "page = 1\n",
    "while True:\n",
    "    url = url_tmpl % page\n",
    "    r = s.get(url)\n",
    "    soup = BeautifulSoup(r.text)\n",
    "    if soup.find(id = 'itemList'):\n",
    "        with open('./all_movies_list/page_%d.html' % page, 'w') as output_file:\n",
    "            output_file.write(r.text.encode('cp1251'))\n",
    "            page += 1\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Парсим выгруженные данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "movies_list = {}\n",
    "\n",
    "for filename in os.listdir('./all_movies_list/'):\n",
    "    if filename.find('html') == -1:\n",
    "        continue\n",
    "    filepath = './all_movies_list/' + filename\n",
    "    \n",
    "    with open(filepath) as input_file:\n",
    "        text = input_file.read()     \n",
    "    \n",
    "    soup = BeautifulSoup(text)\n",
    "    items = soup.find(id = 'itemList').find_all('div', {'class': \"item _NO_HIGHLIGHT_\"})\n",
    "    \n",
    "    for item in items:\n",
    "        name_node = item.find('div', {'class': 'name'})\n",
    "        name_link_node = name_node.find('a')\n",
    "        name = name_link_node.text\n",
    "        link = name_link_node.get('href')\n",
    "        movie_id = pattern.match(link).groups()[0]\n",
    "        \n",
    "        movies_list[movie_id] = name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "movies_list_df = pd.DataFrame.from_dict(movies_list, orient = 'index').reset_index()\n",
    "movies_list_df.columns = ['movie_id', 'name']\n",
    "movies_list_df.to_csv('all_movies_list.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загружаем детальную информацию по фильмам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_movie_data(movie_id, session):\n",
    "    url = 'http://www.kinopoisk.ru/film/%s/' % (movie_id)\n",
    "    #print url\n",
    "    request = session.get(url)\n",
    "    return request.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ! rm -r ./all_movies_data_thread/\n",
    "# ! mkdir all_movies_data_thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36419"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_movies = set(map(lambda x: x.replace('.html', ''), list(os.listdir('./all_movies_data_thread'))))\n",
    "len(loaded_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36418"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_list_df = pd.read_csv('all_movies_list.csv')\n",
    "all_movies = set(map(str, movies_list_df['movie_id'].values.tolist()))\n",
    "len(all_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_to_load = list(all_movies - loaded_movies)\n",
    "len(movies_to_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N = 7\n",
    "kvant = len(movies_to_load)/N\n",
    "movies_chunks = []\n",
    "for i in range(N):\n",
    "    if i != N-1:\n",
    "        movies_chunks.append(movies_to_load[i*kvant:(i+1)*kvant])\n",
    "    else:\n",
    "        movies_chunks.append(movies_to_load[i*kvant:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "class myThread (threading.Thread):\n",
    "    def __init__(self, movies):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.movies = movies\n",
    "    \n",
    "    def run(self):\n",
    "        global loaded_dict\n",
    "        print 'Starting thread...', len(self.movies)\n",
    "        for movie_id in self.movies:\n",
    "            time.sleep(0.1)\n",
    "            tmp = load_movie_data(movie_id, s)\n",
    "            if tmp.find('www.google.com/recaptcha/') != -1:\n",
    "                print 'Looks like CAPTCHA'\n",
    "                break\n",
    "            with open('./all_movies_data_thread/%s.html' % (movie_id), 'w') as output_file:\n",
    "                output_file.write(tmp.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting thread... 1\n",
      "Starting thread... 1\n",
      "Starting thread... 1\n",
      "Starting thread... 1\n",
      "Starting thread... 1\n",
      "Starting thread... 1\n",
      "Starting thread... 1\n"
     ]
    }
   ],
   "source": [
    "for i in range(N):\n",
    "    thread = myThread(movies_chunks[i])\n",
    "    thread.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Распарсим данные о фильмах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! mkdir all_movies_data_parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36417, 36416)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_movies = map(lambda x: x.replace('.html', ''), list(os.listdir('./all_movies_data_thread/')))\n",
    "parsed_movies = map(lambda x: x.replace('.csv', ''), list(os.listdir('./all_movies_data_parsed/')))\n",
    "\n",
    "parsed_movies.remove('.DS_Store')\n",
    "loaded_movies.remove('.DS_Store')\n",
    "\n",
    "loaded_movies = set(loaded_movies)\n",
    "parsed_movies = set(parsed_movies)\n",
    "\n",
    "len(loaded_movies), len(parsed_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_to_parse = loaded_movies - parsed_movies\n",
    "len(movies_to_parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_movie_datafile(filename):\n",
    "    with open('./all_movies_data_thread/' + filename) as input_file:\n",
    "        text = input_file.read().decode('utf-8')\n",
    "        \n",
    "    movie_id = filename.replace('.html', '')\n",
    "    \n",
    "    soup = BeautifulSoup(text)\n",
    "    \n",
    "    name_eng = soup.find('span', {'itemprop': 'alternativeHeadline'}).text\n",
    "    name_rus = soup.find('h1', {'class': 'moviename-big'}).text\n",
    "    \n",
    "    kp_rating = None\n",
    "    if soup.find('span', {'class': 'rating_ball'}):\n",
    "        kp_rating = float(soup.find('span', {'class': 'rating_ball'}).text)\n",
    "    \n",
    "    critics_rating = None\n",
    "    critics_rating_block = soup.find('div', {'class': 'criticsRating'})\n",
    "    if critics_rating_block:\n",
    "        critics_rating_num_block = critics_rating_block.find('div', {'class': 'ratingNum'})\n",
    "        if critics_rating_num_block:\n",
    "            critics_rating = critics_rating_num_block.find('span').text\n",
    "      \n",
    "    imdb_rating = None\n",
    "    if soup.find('div', {'class': 'block_2'}):\n",
    "        imdb_block_text = soup.find('div', {'class': 'block_2'}).find(text = re.compile('^IMDb'))\n",
    "        if imdb_block_text:\n",
    "            imdb_rating = imdb_block_text.split()[1]\n",
    "    \n",
    "    info_table = soup.find('table', {'class': 'info'})\n",
    "    \n",
    "    movie_year = info_table.find('td', {'class': 'type'}, text = u'год').nextSibling.nextSibling.text[:5]\n",
    "    movie_duration = info_table.find('td', {'class': 'type'}, text = u'время').nextSibling.text.split()[0]\n",
    "    \n",
    "    genres = None\n",
    "    if info_table.find('span', {'itemprop': 'genre'}):\n",
    "        genres = map(lambda x: x.text, info_table.find('span', {'itemprop': 'genre'}).find_all('a'))\n",
    "    \n",
    "    countries = map(lambda x: x.text, info_table.find('td', {'class': 'type'}, text = u'страна').nextSibling.nextSibling.find_all('a'))\n",
    "    \n",
    "    movie = {\n",
    "    'movie_id': movie_id,\n",
    "    'name_eng': name_eng,\n",
    "    'name_rus': name_rus,\n",
    "    'kp_rating': kp_rating,\n",
    "    'critics_rating': critics_rating,\n",
    "    'imdb_rating': imdb_rating,\n",
    "    'movie_year': movie_year,\n",
    "    'movie_duration': movie_duration,\n",
    "    'genres': genres,\n",
    "    'countries': countries\n",
    "    }\n",
    "    \n",
    "    return movie\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "failed_movie_ids = []\n",
    "\n",
    "for movie_id in movies_to_parse:\n",
    "    filename = movie_id + '.html'\n",
    "    movie = parse_movie_datafile(filename)\n",
    "    with open('./all_movies_data_parsed/%s.csv' % movie_id, 'w') as output_file:\n",
    "        output_file.write(pd.DataFrame.from_dict(movie, orient = 'index').T.to_csv(encoding = 'utf-8', index = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Соберем распарсенные данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp_dfs = []\n",
    "\n",
    "for filename in os.listdir('./all_movies_data_parsed/'):\n",
    "    if filename == '.DS_Store':\n",
    "        continue\n",
    "    tmp_dfs.append(pd.read_csv('./all_movies_data_parsed/' + filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat(tmp_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.to_csv('kinopoisk_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
